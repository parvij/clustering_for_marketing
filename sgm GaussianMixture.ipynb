{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T07:23:48.720044Z",
     "start_time": "2019-04-03T07:23:48.717313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Task\n",
    "#Done add predict for all player_id\n",
    "#Done restart conda\n",
    "\n",
    "# add K-means\n",
    "# Done add difference in 2 recent weeks\n",
    "# add knee chart\n",
    "# Done add evaluation metrics\n",
    "# other methods of distance\n",
    "\n",
    "\n",
    "# correct_answer_count is wrong surely (see describe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T12:14:24.357337Z",
     "start_time": "2019-04-07T12:14:24.341079Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import ipyvolume as ipv\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from scipy import stats\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "step_to_change = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T18:52:17.115317Z",
     "start_time": "2019-04-11T18:52:17.101081Z"
    }
   },
   "outputs": [],
   "source": [
    "features_catg = [\n",
    "    # lifetime\n",
    "    ['lifetime_recent','lifetime'],\n",
    "    # games played\n",
    "    ['recent_per_total_games','games_per_lifetime_recent','games_per_lifetime','total_game_recent', 'total_game','games_played_recent','games_played'],\n",
    "    # won\n",
    "    [ 'win_per_games_recent', 'win_per_games','won_count_recent','won_count'],\n",
    "    # delete \n",
    "    ['coins_on_hint_delete_wrong_recent','coins_on_hint_delete_wrong', 'times_spent_hint_delete_wrong_recent',     'times_spent_hint_delete_wrong'],\n",
    "    # again\n",
    "    ['times_spent_hint_answer_again','coins_on_hint_answer_again_recent','coins_on_hint_answer_again', 'times_spent_hint_answer_again_recent'],\n",
    "    # unlimited \n",
    "    ['unlimited_play_per_games_recent','unlimited_play_per_spent_recent', 'unlimited_play_per_games','times_spent_unlimited_games','coins_spent_on_unlimited_games_recent','coins_spent_on_unlimited_games',  'times_spent_unlimited_games_recent'],\n",
    "    # avatars\n",
    "    ['change_avatar_per_games_recent','times_change_avatar_per_spent_recent','coins_spent_on_avatars_per_coins_spent_recent','times_changing_avatars','change_avatar_per_games','times_change_avatar_per_spent','coins_spent_on_avatars_recent','coins_spent_on_avatars','times_changing_avatars_recent'],\n",
    "    # freeze \n",
    "    ['coins_on_hint_freeze_time_recent','coins_on_hint_freeze_time','times_spent_hint_freeze_time','times_spent_hint_freeze_time_recent'],\n",
    "    # booster\n",
    "    ['booster_per_games_recent','booster_per_games','times_spent_booster_package','coins_spent_on_booster_package_recent','coins_spent_on_booster_package','times_spent_booster_package_recent'],\n",
    "    # percentage\n",
    "    ['times_hint_answer_percentage','coins_on_hint_answer_per_recent','coins_on_hint_answer_per', 'times_hint_answer_percentage_recent'],\n",
    "    # coin\n",
    "    ['adv_coin_per_games_recent','times_viewing_adv_free_coin','times_viewing_adv_free_coin_recent'],\n",
    "    # extra\n",
    "    ['adv_extra_game_per_games_recent','times_viewing_adv_extra_game','times_viewing_adv_extra_game_recent'],\n",
    "    # perfect\n",
    "    ['perfect_games_recent','perfect_games'],\n",
    "    # won expire\n",
    "    ['win_by_expir_per_games_recent', 'win_by_expir_per_games','won_count_with_expiration','won_count_with_expiration_recent'],\n",
    "    # lose expire\n",
    "    ['lose_by_expir_per_games_recent','lose_by_expir_per_games','lost_count_with_expiration','lost_count_with_expiration_recent'],\n",
    "    # cups\n",
    "    ['tournament_cups','tournament_cups_recent'],\n",
    "    # tournaments\n",
    "    ['tournament_per_games_recent','tournaments_played','tournaments_played_recent'],\n",
    "    # invitation\n",
    "    ['number_of_invitation','number_of_invitation_recent'],\n",
    "    # correct\n",
    "    ['correct_answer_per_games_recent','correct_answer_per_games','correct_answer_count','correct_answer_count_recent'],\n",
    "    # spent\n",
    "    ['total_coins_spent_recent','total_times_spent','total_times_spent_recent','total_coins_spent'],\n",
    "    # guide\n",
    "    ['guide_per_games','guide_per_spent_recent',  'guide_per_games_recent'],\n",
    "    # \n",
    "    ['expir_tech_or_laziness_recent']\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T13:24:40.151231Z",
     "start_time": "2019-04-13T13:24:40.114103Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_eval(n,features,data,features_catg):\n",
    "    modeling_feed=data[features]\n",
    "    #modeling\n",
    "    clustering = GaussianMixture(n_components=n).fit_predict(modeling_feed)\n",
    "    modeling_feed['cat']=clustering\n",
    "    #evaluation\n",
    "    modeling_feed_smp = modeling_feed.sample(frac=0.1, random_state=1)\n",
    "    modeling_feed_smp2 = modeling_feed.sample(frac=0.02, random_state=1)\n",
    "    score_davies_bouldin = davies_bouldin_score(modeling_feed_smp[features],modeling_feed_smp.cat)\n",
    "    my_score = my_score_calc_v2(modeling_feed_smp,features_catg,10)\n",
    "    score_silhouette = 0\n",
    "    if score_davies_bouldin<1.5:\n",
    "        print('+',end='')\n",
    "        score_silhouette = silhouette_score(modeling_feed_smp[features], modeling_feed_smp.cat)\n",
    "        print('*',end='')\n",
    "    elif score_davies_bouldin<3:\n",
    "        print('++',end='')\n",
    "        score_silhouette = silhouette_score(modeling_feed_smp2[features], modeling_feed_smp2.cat)\n",
    "        print('**',end='')\n",
    "    max_cluster = max(modeling_feed.cat.value_counts()/len(modeling_feed)*100)\n",
    "    min_cluster = min(modeling_feed.cat.value_counts()/len(modeling_feed)*100)\n",
    "    #more accurate evaluation\n",
    "    \n",
    "    if (score_silhouette>0.8#best_score \n",
    "        and max_cluster<200/i \n",
    "        and min_cluster>(2**((8-i)-1)+1)): \n",
    "        score_davies_bouldin = davies_bouldin_score(modeling_feed[features],modeling_feed.cat)\n",
    "        score_silhouette = silhouette_score(modeling_feed[features], modeling_feed.cat)\n",
    "        \n",
    "        print({'c':c,\n",
    "              'sil':score_silhouette,\n",
    "              'dav':score_davies_bouldin,\n",
    "              'max_c':max_cluster,\n",
    "              'min_c':min_cluster,\n",
    "              'n_cluster':i})\n",
    "        \n",
    "    return score_silhouette,score_davies_bouldin,my_score,max_cluster,min_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T18:10:30.264582Z",
     "start_time": "2019-04-13T18:10:30.235393Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def features_evaluations(min_n_cluster,max_n_cluster,base_features,available_features,data,features_catg):\n",
    "    import pickle\n",
    "    import os.path\n",
    "    result_columns = ['sign','added_feature','n_cluster','score_silhouette','score_davies_bouldin','my_score','max_cluster','min_cluster','all_features','new_run']\n",
    " \n",
    "    if os.path.isfile('Data/processed_list.pickle'):\n",
    "        with open('Data/processed_list.pickle', 'rb') as f:\n",
    "            processed_list = pickle.load(f)\n",
    "        processed_list.sign='other_results'\n",
    "    else:\n",
    "        processed_list = pd.DataFrame(columns=result_columns)\n",
    "    processed_list.reset_index(inplace=True,drop=True)\n",
    "    clusters_range = range(min_n_cluster,max_n_cluster+1)\n",
    "    #base_features=[ 'coins_spent_on_avatars_per_coins_spent','unlimited_play_per_spent','tournament_per_games','guide_per_games']\n",
    "    processed_list['new_run']=0\n",
    "    print('start calculating')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    feature_list=base_features\n",
    "    for i in clusters_range:\n",
    "        if (len(processed_list[(processed_list.n_cluster==i)&(processed_list.all_features.apply(set)==set(base_features))])==0\n",
    "            and len(feature_list)>0):\n",
    "            print('base',end='')\n",
    "            print(i,end='$')\n",
    "            score_silhouette,score_davies_bouldin,my_score,max_cluster,min_cluster = feature_eval(i,feature_list,data,features_catg)\n",
    "                        \n",
    "            new_row = ['base_features','',i,score_silhouette,score_davies_bouldin,my_score,max_cluster,min_cluster,feature_list,1]\n",
    "            processed_list=processed_list.append(pd.DataFrame(new_row,columns=result_columns), ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            processed_list.loc[(processed_list.n_cluster==i)&(processed_list.all_features.apply(set)==set(feature_list)),['new_run','sign','added_feature']]=[1,'base_features','']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for c in available_features:\n",
    "        if not (is_related_list(c,base_features,features_catg) \n",
    "                or c in base_features):\n",
    "            feature_list=base_features+[c]\n",
    "            for i in clusters_range:\n",
    "                if len(processed_list[(processed_list.n_cluster==i)&(processed_list.all_features.apply(set)==set(feature_list))])==0:\n",
    "                    print(c,end='')\n",
    "                    print(i,end='.')\n",
    "                    score_silhouette,score_davies_bouldin,my_score,max_cluster,min_cluster = feature_eval(i,feature_list,data,features_catg)\n",
    "                    \n",
    "                    \n",
    "                    new_row = ['+',c,i,score_silhouette,score_davies_bouldin,my_score,max_cluster,min_cluster,feature_list,1]\n",
    "                    processed_list=processed_list.append(pd.DataFrame(new_row,columns=result_columns), ignore_index=True)\n",
    "                    \n",
    "                    \n",
    "            else:\n",
    "                processed_list.loc[(processed_list.n_cluster==i)&(processed_list.all_features.apply(set)==set(feature_list)),['new_run','sign','added_feature']]=[1,'+',c]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for c in base_features:\n",
    "        #print('%',c,'%')\n",
    "        feature_list=list(set(base_features)-set([c]))\n",
    "        for i in clusters_range:\n",
    "            try:\n",
    "                print(len(processed_list[(processed_list.n_cluster==i)&((processed_list.all_features.apply(set)==set(feature_list)))]))\n",
    "            except: \n",
    "                print('error 54')\n",
    "            \n",
    "            \n",
    "            \n",
    "            if (len(processed_list[(processed_list.n_cluster==i)&((processed_list.all_features.apply(set)==set(feature_list)))])==0\n",
    "                and len(feature_list)>0):\n",
    "                print(c,end='')\n",
    "                print(i,end=',')\n",
    "                score_silhouette,score_davies_bouldin,my_score,max_cluster,min_cluster = feature_eval(i,feature_list,data,features_catg)\n",
    "                \n",
    "                \n",
    "                \n",
    "                new_row = ['-',c,i,score_silhouette,score_davies_bouldin,my_score,max_cluster,min_cluster,feature_list,1]\n",
    "                processed_list=processed_list.append(pd.DataFrame(new_row,columns=result_columns), ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            processed_list.loc[(processed_list.n_cluster==i)&(processed_list.all_features.apply(set)==set(feature_list)),['new_run','sign','added_feature']]=[1,'-',c]\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    with open('Data/processed_list.pickle', 'wb') as f:\n",
    "        pickle.dump(processed_list, f)\n",
    "\n",
    "    return processed_list.loc[processed_list.new_run==1,['sign','added_feature','n_cluster','score_silhouette','score_davies_bouldin','my_score','max_cluster','min_cluster','all_features']],processed_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T16:04:03.668610Z",
     "start_time": "2019-04-13T16:04:03.644874Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_result(data,n_cluster,features,fraction,true_data):\n",
    "    df=data.copy()\n",
    "    tdf = true_data.copy()\n",
    "    \n",
    "    clustering = GaussianMixture(n_components=n_cluster).fit_predict(df[features])\n",
    "    df['cat']=clustering\n",
    "    tdf['cat'] = clustering\n",
    "    \n",
    "    \n",
    "    df = df.sample(frac=fraction,random_state=1)\n",
    "    tdf = tdf.sample(frac=fraction,random_state=1)\n",
    "    \n",
    "    g1 = sns.countplot(x=\"cat\",data=df)\n",
    "    print(df.cat.value_counts()/len(df)*100)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    rel = pd.DataFrame(columns=['col','score','p_value'])\n",
    "    cat_list = df.cat.unique()\n",
    "    for c in (set(df.columns)-set(['cat'])):\n",
    "        arg=[]\n",
    "        for ct in cat_list:\n",
    "            arg+=[df[df.cat==ct][c]]\n",
    "        s,p=stats.f_oneway(*arg)\n",
    "        rel.loc[len(rel)]=[c,abs(s),p]\n",
    "    print(rel.sort_values(by=['p_value','score'],ascending=[True,False]).head(10))\n",
    "    affected_features = rel.sort_values(by=['p_value','score'],ascending=[True,False]).head(10).col.tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('######### with transformed data ##########')\n",
    "    coln = len(df.columns)-1\n",
    "    fig,axes = plt.subplots(1,3,figsize=(16,2))\n",
    "    i=0\n",
    "    for c in df.columns:\n",
    "        if c in set(features+affected_features):\n",
    "            sns.factorplot( y= c,x = \"cat\",data = df, kind=\"violin\",ax=axes[i%3],scale=\"width\")\n",
    "            i+=1\n",
    "            plt.close(2)\n",
    "            if i%3==0:\n",
    "                plt.show()\n",
    "                if i!=coln:\n",
    "                    fig,axes = plt.subplots(1,3,figsize=(16,2))\n",
    "    plt.show()                \n",
    "                    \n",
    "    print('######### with True data ##########')\n",
    "    coln = len(tdf.columns)-1\n",
    "    fig,axes = plt.subplots(1,3,figsize=(16,2))\n",
    "    i=0\n",
    "    for c in tdf.columns:\n",
    "        if c in set(features+affected_features):\n",
    "            sns.factorplot( y= c,x = \"cat\",data = tdf, kind=\"violin\",ax=axes[i%3],scale=\"width\")\n",
    "            i+=1\n",
    "            plt.close(2)\n",
    "            if i%3==0:\n",
    "                plt.show()\n",
    "                if i!=coln:\n",
    "                    fig,axes = plt.subplots(1,3,figsize=(16,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T16:04:09.840213Z",
     "start_time": "2019-04-13T16:04:09.838061Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_related_list(c,l,features_catg):\n",
    "    for c2 in l:\n",
    "        if is_related(c,c2,features_catg):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T16:04:15.945982Z",
     "start_time": "2019-04-13T16:04:15.943672Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_related(c1,c2,features_catg):\n",
    "    for i in range(len(features_catg)):\n",
    "        if c1 in features_catg[i] and c2 in features_catg[i]:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T11:52:02.297548Z",
     "start_time": "2019-04-13T11:32:53.327477Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def correct_score(data,features,n,features_catg):\n",
    "    modeling_feed=data[features]\n",
    "    #modeling\n",
    "    clustering = GaussianMixture(n_components=n).fit_predict(modeling_feed)\n",
    "    modeling_feed['cat']=clustering\n",
    "    print(features,n)\n",
    "    return my_score_calc_v2(modeling_feed,features_catg,10)\n",
    "\n",
    "all_result.my_score = all_result.apply(lambda r: correct_score(df7.sample(frac=0.2,random_state=1),r.all_features,r.n_cluster,features_catg),axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T06:50:12.478419Z",
     "start_time": "2019-04-12T06:50:12.463185Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def my_score_calc(df,features_catg,n_first):\n",
    "    rel = pd.DataFrame(columns=['col','score','p_value'])\n",
    "    cat_list = df.cat.unique()\n",
    "    for c in (set(df.columns)-set(['cat'])):\n",
    "        arg=[]\n",
    "        for ct in cat_list:\n",
    "            arg+=[df[df.cat==ct][c]]\n",
    "        s,p=stats.f_oneway(*arg)\n",
    "        rel.loc[len(rel)]=[c,abs(s),p]\n",
    "    try:\n",
    "        affected_features = rel.sort_values(by=['p_value','score'],ascending=[True,False]).col.tolist()\n",
    "    except:\n",
    "        print(rel)\n",
    "    score=0\n",
    "    for cl in range(len(affected_features)):\n",
    "        clp=cl-1\n",
    "        while clp>=0:\n",
    "            if is_related(affected_features[cl],affected_features[clp],features_catg):\n",
    "                break\n",
    "            clp-=1\n",
    "        if clp==-1:\n",
    "            score += rel[rel.col==affected_features[cl]].score.iloc[0]\n",
    "            n_first-=1\n",
    "            if n_first==0:\n",
    "                break\n",
    "    return score\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T16:16:43.245284Z",
     "start_time": "2019-04-13T16:16:43.229036Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_score_calc_v2(df,features_catg,n_first):\n",
    "    rel = pd.DataFrame(columns=['col','score','p_value'])\n",
    "    cat_list = df.cat.unique()\n",
    "    for c in (set(df.columns)-set(['cat'])):\n",
    "        arg=[]\n",
    "        for ct in cat_list:\n",
    "            arg+=[df[df.cat==ct][c]]\n",
    "        s,p=stats.f_oneway(*arg)\n",
    "        rel.loc[len(rel)]=[c,abs(s),p]\n",
    "    try:\n",
    "        affected_features = rel.sort_values(by=['p_value','score'],ascending=[True,False]).col.tolist()\n",
    "    except:\n",
    "        print('Error',rel)\n",
    "    score=0\n",
    "    cl=0\n",
    "    inf = 0\n",
    "    while n_first>0 and cl<len(affected_features):\n",
    "        if not is_related_list(affected_features[cl],affected_features[:cl],features_catg):\n",
    "            try:\n",
    "                score += round(math.log(rel[rel.col==affected_features[cl]].score.iloc[0],10))\n",
    "                score += inf * score #add max instead of infinity\n",
    "                inf = 0 \n",
    "            except: # score = infinity\n",
    "                inf+=1\n",
    "            n_first-=1\n",
    "        cl+=1\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T16:04:28.120272Z",
     "start_time": "2019-04-13T16:04:28.117254Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_result(data,n_cluster,features,player_id,name):\n",
    "    df=data[features]\n",
    "    \n",
    "    clustering = GaussianMixture(n_components=n_cluster).fit_predict(df)\n",
    "    df['cat']=clustering\n",
    "    df['player_id'] = player_id\n",
    "    filename = 'cats__'+name+'__'+str(n_cluster)+'__'+str(features)+'.csv'\n",
    "    df[['player_id','cat']].to_csv(filename,index=False)\n",
    "    print('Done: saving '+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T05:30:13.632625Z",
     "start_time": "2019-04-06T05:30:13.625431Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def sil_coeff(no_clusters,data,show=False):\n",
    "    # Apply your clustering algorithm of choice to the reduced data\n",
    "    clustering = GaussianMixture(n_components=5).fit_predict(data)\n",
    "    score = silhouette_score(data, clustering)\n",
    "    '''\n",
    "    clusterer_1 = KMeans(n_clusters=no_clusters, random_state=0 )\n",
    "    clusterer_1.fit(data)\n",
    "    \n",
    "    # Predict the cluster for each data point\n",
    "    preds_1 = clusterer_1.predict(data)\n",
    "    \n",
    "    # Calculate the mean silhouette coefficient for the number of clusters chosen\n",
    "    score = silhouette_score(data, preds_1)\n",
    "    '''\n",
    "    if show:\n",
    "        sns.factorplot( y= 'val',x = \"cat\",data = data, kind=\"violin\")\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:32:40.310249Z",
     "start_time": "2019-04-04T18:32:40.164630Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def silh(X_scaled):\n",
    "    K_best=8\n",
    "    cluster_centers = dict()\n",
    "\n",
    "    for n_clusters in range(3,K_best+1,1):\n",
    "        fig, ax1 = plt.subplots(1, 1)\n",
    "        #fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "        fig.set_size_inches(25, 7)\n",
    "        ax1.set_xlim([-0.1, 1])\n",
    "        ax1.set_ylim([0, len(X_scaled) + (n_clusters + 1) * 10])\n",
    "\n",
    "        clusterer = KMeans(n_clusters=n_clusters, init='k-means++', n_init=10,max_iter=300, tol=1e-04, random_state=101)\n",
    "        cluster_labels = clusterer.fit_predict(X_scaled)\n",
    "\n",
    "        silhouette_avg = silhouette_score(X = X_scaled, labels = cluster_labels)\n",
    "        cluster_centers.update({n_clusters :{'cluster_center':clusterer.cluster_centers_,\n",
    "                                             'silhouette_score':silhouette_avg,\n",
    "                                             'labels':cluster_labels}\n",
    "                               })\n",
    "\n",
    "        sample_silhouette_values = silhouette_samples(X = X_scaled, labels = cluster_labels)\n",
    "        y_lower = 10\n",
    "        for i in range(n_clusters):\n",
    "            ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.Spectral(float(i) / n_clusters)\n",
    "            ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                              0, ith_cluster_silhouette_values,\n",
    "                              facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "        ax1.set_title(\"The silhouette plot for the various clusters\")\n",
    "        ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "        ax1.set_ylabel(\"Cluster label\")\n",
    "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "        ax1.set_yticks([])\n",
    "        ax1.set_xticks([-0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "        colors = cm.Spectral(cluster_labels.astype(float) / n_clusters)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:33:07.939570Z",
     "start_time": "2019-04-04T18:32:40.319924Z"
    }
   },
   "outputs": [],
   "source": [
    "newdata=pd.read_csv('Data/2019_03_29.csv', error_bad_lines=False)\n",
    "\n",
    "newdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:33:33.440000Z",
     "start_time": "2019-04-04T18:33:08.748104Z"
    }
   },
   "outputs": [],
   "source": [
    "pastdata=pd.read_csv('Data/2019_03_14.csv', error_bad_lines=False)\n",
    "\n",
    "pastdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:33:50.759551Z",
     "start_time": "2019-04-04T18:33:34.998345Z"
    }
   },
   "outputs": [],
   "source": [
    "data = newdata.merge(right=pastdata, how='inner',left_on='player_id',right_on='player_id', sort=False,suffixes=('', '_past'))\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### number_of_invitation (-1 to 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:33:53.891306Z",
     "start_time": "2019-04-04T18:33:53.888732Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def correct_minues_one(newdata):\n",
    "    newdata.loc[newdata.number_of_invitation<0,'number_of_invitation']=0\n",
    "    newdata.loc[newdata.correct_answer_count<0,'correct_answer_count']=0\n",
    "    print(newdata.shape)\n",
    "    return newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:00.092544Z",
     "start_time": "2019-04-04T18:33:57.062571Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_data = correct_minues_one(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reducing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T08:44:28.934610Z",
     "start_time": "2019-03-24T08:44:28.930891Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## defining steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### delete inactive users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:03.239490Z",
     "start_time": "2019-04-04T18:34:03.236982Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def delete_inactive_users_v3(data):\n",
    "    df=data.copy()\n",
    "    \n",
    "    df = df[df.games_played>10]\n",
    "    df = df[df.games_played>df.games_played_past]\n",
    "    \n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T16:23:54.123791Z",
     "start_time": "2019-03-31T16:23:53.987627Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def delete_inactive_users_v2(data):\n",
    "    df=data.copy()\n",
    "    df.updated_at = df.updated_at.apply(lambda x:datetime.strptime(x[:10],'%Y-%m-%d'))\n",
    "    df = df[df.updated_at>=datetime.strptime('2019-03-01','%Y-%m-%d')]\n",
    "    df = df[df.games_played>10]\n",
    "    print(df.shape)\n",
    "    return df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def delete_inactive_users(newdata,olddata):\n",
    "    previous_games_played = olddata[['player_id','games_played','created_at']]\n",
    "    previous_games_played.columns = ['player_id','previous_games_played','previous_created_at']\n",
    "\n",
    "    newdata_withprevious_games_count = newdata.merge(right=previous_games_played, how='inner',left_on='player_id',right_on='player_id', sort=False)\n",
    "\n",
    "    active_users = newdata_withprevious_games_count[newdata_withprevious_games_count.games_played>newdata_withprevious_games_count.previous_games_played]\n",
    "    active_users = active_users[active_users.games_played>5]\n",
    "    print('Done: delete_inactive_users')\n",
    "    return active_users\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### delete non-buyer users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:06.384752Z",
     "start_time": "2019-04-04T18:34:06.382530Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def none_buyer(data):\n",
    "    df=data.copy()\n",
    "    result = df[df.purchased_times==0]\n",
    "    print(result.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### calculate lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:09.568396Z",
     "start_time": "2019-04-04T18:34:09.565460Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def add_lifetime_v2(data):\n",
    "    df=data.copy()\n",
    "    df.qok_created_at = df.qok_created_at.apply(lambda x:datetime.strptime(x[:10],'%Y-%m-%d'))\n",
    "    df['lifetime'] = (max(df.qok_created_at) - df.qok_created_at).apply(lambda x:x.days)+1\n",
    "    df['lifetime_recent'] = 15\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:16.965756Z",
     "start_time": "2019-04-04T18:34:12.704514Z"
    }
   },
   "outputs": [],
   "source": [
    "dr1 = delete_inactive_users_v3(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:20.602946Z",
     "start_time": "2019-04-04T18:34:20.325042Z"
    }
   },
   "outputs": [],
   "source": [
    "dr2 = none_buyer(dr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:32.502519Z",
     "start_time": "2019-04-04T18:34:24.568059Z"
    }
   },
   "outputs": [],
   "source": [
    "dr3 = add_lifetime_v2(dr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:36.904601Z",
     "start_time": "2019-04-04T18:34:36.725394Z"
    }
   },
   "outputs": [],
   "source": [
    "reduced_data = dr3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature_engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T08:52:10.867216Z",
     "start_time": "2019-03-24T08:52:10.861870Z"
    }
   },
   "source": [
    "## defining steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define recents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:41.789810Z",
     "start_time": "2019-04-04T18:34:41.786702Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_recents(data):\n",
    "    df=data.copy()\n",
    "    for c in df.columns:\n",
    "        if c not in ['player_id','updated_at','created_at','account_id','qok_created_at'] and\\\n",
    "           c+'_past' in df.columns:\n",
    "            df[c+'_recent'] = df[c]-df[c+'_past']\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total coin & coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:46.723417Z",
     "start_time": "2019-04-04T18:34:46.719228Z"
    }
   },
   "outputs": [],
   "source": [
    "def cal_total_times_n_coins(data):\n",
    "    df=data.copy()\n",
    "    for c in ['','_recent']:\n",
    "        df['total_times_spent'+c] =df['times_spent_hint_delete_wrong'+c]+\\\n",
    "                                        df['times_spent_hint_answer_again'+c]+\\\n",
    "                                        df['times_spent_unlimited_games'+c]+\\\n",
    "                                        df['times_changing_avatars'+c]+\\\n",
    "                                        df['times_spent_hint_freeze_time'+c]+\\\n",
    "                                        df['times_spent_booster_package'+c]+\\\n",
    "                                        df['times_hint_answer_percentage'+c]+\\\n",
    "                                        df['tournaments_played'+c] + 1\n",
    "\n",
    "        df['total_coins_spent'+c]=df['coins_on_hint_delete_wrong'+c]+\\\n",
    "                                        df['coins_on_hint_answer_again'+c]+\\\n",
    "                                        df['coins_spent_on_unlimited_games'+c]+\\\n",
    "                                        df['coins_spent_on_avatars'+c]+\\\n",
    "                                        df['coins_on_hint_freeze_time'+c]+\\\n",
    "                                        df['coins_spent_on_booster_package'+c]+\\\n",
    "                                        df['coins_on_hint_answer_per'+c]+\\\n",
    "                                        (df['tournaments_played'+c]*15)+\\\n",
    "                                        (df['lost_count_with_expiration'+c]*50) + 1\n",
    "\n",
    "\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### round features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:51.670527Z",
     "start_time": "2019-04-04T18:34:51.668012Z"
    }
   },
   "outputs": [],
   "source": [
    "def round_some_features(data):\n",
    "    df=data.copy()\n",
    "    df.games_played=round(df.games_played,-1)\n",
    "    df.games_played_recent = round(df.games_played_recent,-1)\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove unrelated col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:34:56.691952Z",
     "start_time": "2019-04-04T18:34:56.688266Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_unrelated_column_to_project(data):\n",
    "    df=data.copy()\n",
    "    col_list = [\n",
    "        'lifetime',\n",
    "       'games_played',  \n",
    "        'won_count', \n",
    "\n",
    "        'coins_on_hint_delete_wrong',\n",
    "        'coins_on_hint_answer_again',\n",
    "        'coins_spent_on_unlimited_games',\n",
    "        'coins_spent_on_avatars',\n",
    "        'coins_on_hint_freeze_time',\n",
    "        'coins_spent_on_booster_package',\n",
    "        'coins_on_hint_answer_per',\n",
    "                                 \n",
    "        'times_spent_hint_freeze_time',\n",
    "        'times_spent_hint_delete_wrong',\n",
    "        'times_spent_hint_answer_again',\n",
    "        'times_hint_answer_percentage',\n",
    "        'times_spent_booster_package',\n",
    "                                 \n",
    "       'times_spent_unlimited_games',\n",
    "       'times_changing_avatars',\n",
    "                                 \n",
    "        'times_viewing_adv_free_coin', \n",
    "        'times_viewing_adv_extra_game',\n",
    "\n",
    "        'perfect_games', \n",
    "        'won_count_with_expiration',\n",
    "        'lost_count_with_expiration',\n",
    "                                 \n",
    "        'tournament_cups',\n",
    "        'tournaments_played', \n",
    "        'number_of_invitation',\n",
    "        'correct_answer_count']\n",
    "    col_list += [s+'_recent' if s+'_recent' in df.columns else s+'_past' for s in col_list]\n",
    "    result = df[col_list]\n",
    "    print(result.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:35:01.806912Z",
     "start_time": "2019-04-04T18:35:01.798070Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_derived_features(data):\n",
    "    df=data.copy()\n",
    "    for c in ['','_recent']:\n",
    "        df['total_game'+c] = (df['games_played'+c]+df['tournaments_played'+c])\n",
    "        df['coins_spent_on_avatars_per_coins_spent'+c]=df['coins_spent_on_avatars'+c]/df['total_coins_spent'+c]\n",
    "\n",
    "        df['unlimited_play_per_spent'+c] = df['times_spent_unlimited_games'+c] / df['total_times_spent'+c]\n",
    "        df['times_change_avatar_per_spent'+c] = df['times_changing_avatars'+c] / df['total_times_spent'+c]\n",
    "        df['guide_per_spent'+c] = (df['times_spent_hint_answer_again'+c]+\n",
    "                                                df['times_spent_hint_delete_wrong'+c]+\n",
    "                                                df['times_spent_hint_freeze_time'+c]+\n",
    "                                                df['times_hint_answer_percentage'+c])/df['total_times_spent'+c]\n",
    "\n",
    "\n",
    "        df['booster_per_games'+c] = df['times_spent_booster_package'+c] / df['total_game'+c]\n",
    "        df['unlimited_play_per_games'+c] = df['times_spent_unlimited_games'+c] / df['total_game'+c]\n",
    "        df['change_avatar_per_games'+c] = df['times_changing_avatars'+c] / df['total_game'+c]\n",
    "        df['guide_per_games'+c] = (df['times_spent_hint_answer_again'+c]+\n",
    "                                                df['times_spent_hint_delete_wrong'+c]+\n",
    "                                                df['times_spent_hint_freeze_time'+c]+\n",
    "                                                df['times_hint_answer_percentage'+c])/df['total_game'+c]\n",
    "\n",
    "        df['win_per_games'+c] = df['won_count'+c] / df['total_game'+c]\n",
    "\n",
    "        df['adv_coin_per_games'+c] = df['times_viewing_adv_free_coin'+c] / df['total_game'+c]\n",
    "        df['adv_extra_game_per_games'+c] = df['times_viewing_adv_extra_game'+c] / df['total_game'+c]\n",
    "\n",
    "        df['games_per_lifetime'+c] = df['total_game'+c] / df['lifetime'+c]\n",
    "\n",
    "        df['tournament_per_games'+c] = df['tournaments_played'+c] / df['total_game'+c]\n",
    "\n",
    "        df['correct_answer_per_games'+c] = df['correct_answer_count'+c] / df['total_game'+c]\n",
    "\n",
    "        df['win_by_expir_per_games'+c] = df['won_count_with_expiration'+c] / df['games_played'+c]\n",
    "        df['lose_by_expir_per_games'+c] = df['lost_count_with_expiration'+c] / df['games_played'+c]\n",
    "\n",
    "        df['expir_tech_or_laziness'+c] = df['won_count_with_expiration'+c] / (df['lost_count_with_expiration'+c]+1)\n",
    "\n",
    "        \n",
    "\n",
    "        df['save'+c] = (df['won_count'+c]*20+\\\n",
    "                                      df['times_viewing_adv_free_coin'+c]*30+\\\n",
    "                                      df['number_of_invitation'+c]*200+\n",
    "                                      df['tournament_cups'+c]*70)\\\n",
    "                                    -df['total_coins_spent'+c]\n",
    "        \n",
    "        \n",
    "    df['recent_per_total_games'] = df['games_played_recent']/df['total_game']\n",
    "    \n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove outliers & extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T08:48:45.852788Z",
     "start_time": "2019-04-05T08:48:45.849824Z"
    }
   },
   "outputs": [],
   "source": [
    "def fix_outliers(data):\n",
    "    df=data.copy()\n",
    "    for c in df.columns: \n",
    "        df.loc[df[c]>=df[c].quantile(.9995),c] = df[c].quantile(.9995)\n",
    "        df.loc[df[c]<=df[c].quantile(.0005),c] = df[c].quantile(.0005)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T08:53:45.419642Z",
     "start_time": "2019-04-05T08:53:45.409978Z"
    }
   },
   "outputs": [],
   "source": [
    "def features_selection(data,selected_features):\n",
    "    df=data.copy()\n",
    "    per_list=[]\n",
    "    recent_list=[]\n",
    "    others_list=[]\n",
    "    for c in df.columns:\n",
    "        if c not in selected_features:\n",
    "            if 'recent' in c:\n",
    "                recent_list+=[c]\n",
    "            elif 'per' in c:\n",
    "                per_list+=[c]\n",
    "            else:\n",
    "                others_list+=[c]\n",
    "    print(df[main_features].shape)\n",
    "    print('recent:',recent_list,'\\n')\n",
    "    print('per:',per_list,'\\n')\n",
    "    print('others',others_list)\n",
    "    return df[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:35:11.781447Z",
     "start_time": "2019-04-04T18:35:11.778066Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    result = data.copy()\n",
    "    for c in result.columns:\n",
    "        if c not in ['win_per_games','player_id','win_per_games_recent','player_id_past']:\n",
    "            x=result[c]-min(result[c])+1\n",
    "            xt, _ = stats.boxcox(x)\n",
    "            result[c] = xt\n",
    "            result[c] = result[c].apply(lambda x: round(x,2))\n",
    "    print(result.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:35:16.718286Z",
     "start_time": "2019-04-04T18:35:16.715266Z"
    }
   },
   "outputs": [],
   "source": [
    "def sampling(trans_data,true_data,sample_fraction):\n",
    "    idx = pd.DataFrame({'i':true_data.index})\n",
    "    smp = idx.sample(frac=sample_fraction, random_state=1)\n",
    "    idx_smp = smp['i'].tolist()\n",
    "    true_data = true_data.ix[idx_smp]\n",
    "    trans_data = trans_data.ix[idx_smp]\n",
    "    #clustering_data_samp = data.sample(frac=sample_fraction, random_state=1)\n",
    "    print(trans_data.shape,true_data.shape)\n",
    "    return trans_data,true_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:35:21.884372Z",
     "start_time": "2019-04-04T18:35:21.879278Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def pca_results(good_data, pca,ax):\n",
    "    '''\n",
    "    Create a DataFrame of the PCA results\n",
    "    Includes dimension feature weights and explained variance\n",
    "    Visualizes the PCA results\n",
    "    '''\n",
    "\n",
    "    # Dimension indexing\n",
    "    dimensions = dimensions = ['Dimension {}'.format(i) for i in range(1,len(pca.components_)+1)]\n",
    "\n",
    "    # PCA components\n",
    "    components = pd.DataFrame(np.round(pca.components_, 4), columns = list(good_data.keys()))\n",
    "    components.index = dimensions\n",
    "\n",
    "    # PCA explained variance\n",
    "    ratios = pca.explained_variance_ratio_.reshape(len(pca.components_), 1)\n",
    "    variance_ratios = pd.DataFrame(np.round(ratios, 4), columns = ['Explained Variance'])\n",
    "    variance_ratios.index = dimensions\n",
    "\n",
    "    # Create a bar plot visualization\n",
    "    #fig, ax = plt.subplots(figsize = (14,8))\n",
    "\n",
    "    # Plot the feature weights as a function of the components\n",
    "    components.plot(ax = ax, kind = 'bar');\n",
    "    ax.set_ylabel(\"Feature Weights\")\n",
    "    ax.set_xticklabels(dimensions, rotation=0)\n",
    "\n",
    "\n",
    "    # Display the explained variance ratios\n",
    "    for i, ev in enumerate(pca.explained_variance_ratio_):\n",
    "        ax.text(i-0.40, ax.get_ylim()[1] + 0.05, \"Explained Variance\\n          %.4f\"%(ev))\n",
    "\n",
    "    # Return a concatenated DataFrame\n",
    "    return pd.concat([variance_ratios, components], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:35:27.073589Z",
     "start_time": "2019-04-04T18:35:27.067821Z"
    }
   },
   "outputs": [],
   "source": [
    "def pca(data,n_comp):\n",
    "    fig, ax = plt.subplots(figsize=(6+n_comp*3,2+n_comp*3)) \n",
    "    from sklearn.decomposition import PCA\n",
    "    pca_feed=data.copy()\n",
    "    # Apply PCA by fitting the good data with the same number of dimensions as features\n",
    "    pca = PCA(n_components = n_comp, random_state=0)\n",
    "    pca.fit(pca_feed)\n",
    "\n",
    "    # Transform log_samples using the PCA fit above\n",
    "    pca_t = pca.transform(pca_feed)\n",
    "    print(\"Explained Variance Ratio => {}\\n\".format(pca.explained_variance_ratio_))\n",
    "    print(\"Explained Variance Ratio(csum) => {}\\n\".format(pca.explained_variance_ratio_.cumsum()))\n",
    "\n",
    "    # Generate PCA results plot\n",
    "    dim_var = pca_results(pca_feed, pca,ax)\n",
    "    dv = dim_var.pivot_table(values=list(set(dim_var.columns)-set(['Explained Variance'])),columns=list(dim_var.index))\n",
    "    dv2 = dv.copy()\n",
    "    for d in dv2.columns:\n",
    "        dv2[d] = dv2[d].apply(abs)\n",
    "        dv2.sort_values(by=d,inplace=True,ascending=False)\n",
    "        v1 = set(dv2[dv2[d]>0.25].index)\n",
    "        v2 = set(dv2.index[[0,1]])\n",
    "        #print(d,(v1|v2))\n",
    "        print(d,end='\\t')\n",
    "        for v in list(v2|v1):\n",
    "            print(v,dv.loc[v,d],end='\\t')\n",
    "        print('')\n",
    "\n",
    "    print(pca_t.shape)\n",
    "    return pca_t,pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:35:32.458510Z",
     "start_time": "2019-04-04T18:35:32.272321Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = define_recents(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:35:37.970851Z",
     "start_time": "2019-04-04T18:35:37.547758Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2 = remove_unrelated_column_to_project(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:35:43.152917Z",
     "start_time": "2019-04-04T18:35:43.103958Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3 = cal_total_times_n_coins(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T18:35:48.525971Z",
     "start_time": "2019-04-04T18:35:48.299399Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = create_derived_features(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T08:55:28.799980Z",
     "start_time": "2019-04-05T08:55:28.754916Z"
    }
   },
   "outputs": [],
   "source": [
    "#df5 = round_some_features(df4)\n",
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T08:55:56.467640Z",
     "start_time": "2019-04-05T08:55:50.845804Z"
    }
   },
   "outputs": [],
   "source": [
    "df6 = fix_outliers(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T08:57:18.530482Z",
     "start_time": "2019-04-05T08:56:18.354547Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df7 = transform(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T08:57:40.685949Z",
     "start_time": "2019-04-05T08:57:40.641978Z"
    }
   },
   "outputs": [],
   "source": [
    "main_features=[ \n",
    "    \n",
    "    #'win_by_expir_per_games',\n",
    "    'expir_tech_or_laziness',\n",
    "    #'win_per_games',\n",
    "    'guide_per_spent',\n",
    "\n",
    "    'coins_spent_on_avatars_per_coins_spent',\n",
    "    \n",
    "    'unlimited_play_per_spent',\n",
    "    'tournament_per_games',\n",
    "    'adv_extra_game_per_games', \n",
    "    \n",
    "    'adv_coin_per_games' \n",
    "    #stable\n",
    "    #'recent_per_total_games'\n",
    "]\n",
    "df8 = features_selection(df7,main_features) #main features , all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T08:53:54.659761Z",
     "start_time": "2019-04-13T08:53:54.584517Z"
    }
   },
   "outputs": [],
   "source": [
    "data_trans = df7.copy()\n",
    "true_data = df6.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diminish data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T16:55:56.662454Z",
     "start_time": "2019-04-05T16:55:56.637491Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_pca(data_trans,true_data):\n",
    "    if data_trans.isnull().values.any():\n",
    "        data_trans.info()\n",
    "        return\n",
    "    dd1,true_data_smp = sampling(data_trans,true_data,0.05)\n",
    "    dd2, pca_fitted = pca(dd1,10)\n",
    "    dd3 = dd2[:,range(0,10)]\n",
    "    return pca_fitted.transform(data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T16:56:26.128130Z",
     "start_time": "2019-04-05T16:56:26.107355Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_kmeans(data):\n",
    "    kmeans = KMeans(n_clusters = 200, init = 'k-means++', max_iter = 100, n_init = 10, random_state = 0)\n",
    "    kmeans.fit(data.sample(frac=0.15, random_state=1))\n",
    "\n",
    "    _, counts = np.unique(kmeans.labels_, return_counts=True)\n",
    "    print(stats.describe(counts))\n",
    "    df = kmeans.predict(data)\n",
    "    return kmeans.cluster_centers_, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-04T10:38:22.034630Z",
     "start_time": "2019-04-04T10:38:22.031342Z"
    }
   },
   "source": [
    "## pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T16:56:55.593689Z",
     "start_time": "2019-04-05T16:56:55.587923Z"
    }
   },
   "outputs": [],
   "source": [
    "active_PCA =False\n",
    "if active_PCA:\n",
    "    print('PCA: ON')\n",
    "    dd0 = do_pca(data_trans,true_data)\n",
    "else:\n",
    "    print('PCA: OFF')\n",
    "    dd0 = data_trans.copy()\n",
    "\n",
    "dd1 = pd.DataFrame(data=dd0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T16:57:25.072036Z",
     "start_time": "2019-04-05T16:57:25.067858Z"
    }
   },
   "outputs": [],
   "source": [
    "modeling_feed = dd3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T08:52:45.753773Z",
     "start_time": "2019-04-13T08:52:45.744813Z"
    }
   },
   "outputs": [],
   "source": [
    "_=[\n",
    "    # lifetime\n",
    "    ['lifetime_recent','lifetime'],\n",
    "    # games played\n",
    "    ['recent_per_total_games','games_per_lifetime_recent','games_per_lifetime','total_game_recent', 'total_game','games_played_recent','games_played'],\n",
    "    # won\n",
    "    [ 'win_per_games_recent', 'win_per_games','won_count_recent','won_count'],\n",
    "    # delete \n",
    "    ['coins_on_hint_delete_wrong_recent','coins_on_hint_delete_wrong', 'times_spent_hint_delete_wrong_recent',     'times_spent_hint_delete_wrong'],\n",
    "    # again\n",
    "    ['times_spent_hint_answer_again','coins_on_hint_answer_again_recent','coins_on_hint_answer_again', 'times_spent_hint_answer_again_recent'],\n",
    "    # unlimited \n",
    "    ['unlimited_play_per_games_recent','unlimited_play_per_spent_recent', 'unlimited_play_per_games','times_spent_unlimited_games','coins_spent_on_unlimited_games_recent','coins_spent_on_unlimited_games',  'times_spent_unlimited_games_recent'],\n",
    "    # avatars\n",
    "    ['change_avatar_per_games_recent','times_change_avatar_per_spent_recent','coins_spent_on_avatars_per_coins_spent_recent','times_changing_avatars','change_avatar_per_games','times_change_avatar_per_spent','coins_spent_on_avatars_recent','coins_spent_on_avatars','times_changing_avatars_recent'],\n",
    "    # freeze \n",
    "    ['coins_on_hint_freeze_time_recent','coins_on_hint_freeze_time','times_spent_hint_freeze_time','times_spent_hint_freeze_time_recent'],\n",
    "    # booster\n",
    "    ['booster_per_games_recent','booster_per_games','times_spent_booster_package','coins_spent_on_booster_package_recent','coins_spent_on_booster_package','times_spent_booster_package_recent'],\n",
    "    # percentage\n",
    "    ['times_hint_answer_percentage','coins_on_hint_answer_per_recent','coins_on_hint_answer_per', 'times_hint_answer_percentage_recent'],\n",
    "    # coin\n",
    "    ['adv_coin_per_games_recent','times_viewing_adv_free_coin','times_viewing_adv_free_coin_recent'],\n",
    "    # extra\n",
    "    ['adv_extra_game_per_games_recent','times_viewing_adv_extra_game','times_viewing_adv_extra_game_recent'],\n",
    "    # perfect\n",
    "    ['perfect_games_recent','perfect_games'],\n",
    "    # won expire\n",
    "    ['win_by_expir_per_games_recent', 'win_by_expir_per_games','won_count_with_expiration','won_count_with_expiration_recent'],\n",
    "    # lose expire\n",
    "    ['lose_by_expir_per_games_recent','lose_by_expir_per_games','lost_count_with_expiration','lost_count_with_expiration_recent'],\n",
    "    # cups\n",
    "    ['tournament_cups','tournament_cups_recent'],\n",
    "    # tournaments\n",
    "    ['tournament_per_games_recent','tournaments_played','tournaments_played_recent'],\n",
    "    # invitation\n",
    "    ['number_of_invitation','number_of_invitation_recent'],\n",
    "    # correct\n",
    "    ['correct_answer_per_games_recent','correct_answer_per_games','correct_answer_count','correct_answer_count_recent'],\n",
    "    # spent\n",
    "    ['total_coins_spent_recent','total_times_spent','total_times_spent_recent','total_coins_spent'],\n",
    "    # guide\n",
    "    ['guide_per_games','guide_per_spent_recent',  'guide_per_games_recent'],\n",
    "    # \n",
    "    ['expir_tech_or_laziness_recent']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-14T15:34:47.243Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#all available features\n",
    "#new_list = data_trans.columns \n",
    "\n",
    "# without recent\n",
    "new_list = ['coins_on_hint_answer_per', 'times_hint_answer_percentage', 'perfect_games', 'times_change_avatar_per_spent', 'booster_per_games', 'unlimited_play_per_games', 'change_avatar_per_games', 'guide_per_games', 'win_per_games', 'games_per_lifetime', 'correct_answer_per_games', 'win_by_expir_per_games', 'lose_by_expir_per_games','lifetime', 'games_played', 'won_count', 'coins_on_hint_delete_wrong', 'coins_on_hint_answer_again', 'coins_spent_on_unlimited_games', 'coins_spent_on_avatars', 'coins_on_hint_freeze_time', 'coins_spent_on_booster_package', 'times_spent_hint_freeze_time', 'times_spent_hint_delete_wrong', 'times_spent_hint_answer_again', 'times_spent_booster_package', 'times_spent_unlimited_games', 'times_changing_avatars', 'times_viewing_adv_free_coin', 'times_viewing_adv_extra_game', 'won_count_with_expiration', 'lost_count_with_expiration', 'tournament_cups', 'tournaments_played', 'number_of_invitation', 'correct_answer_count', 'total_times_spent', 'total_coins_spent', 'total_game', 'save']\n",
    "\n",
    "base_features = ['coins_spent_on_avatars_per_coins_spent','coins_on_hint_freeze_time_recent']\n",
    "\n",
    "result, all_result = \\\n",
    "    features_evaluations(min_n_cluster=3,\n",
    "                        max_n_cluster=4,\n",
    "                        base_features= base_features,\n",
    "                        available_features = new_list,\n",
    "                        data = data_trans,\n",
    "                        features_catg = features_catg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T16:08:07.928848Z",
     "start_time": "2019-04-13T16:08:07.910624Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T10:03:59.804399Z",
     "start_time": "2019-04-13T10:03:59.760841Z"
    }
   },
   "outputs": [],
   "source": [
    "result[#(result.score_silhouette>0.8)& # filter on silhouette score\n",
    "               (result.min_cluster>1)& # size of smallest cluster in percentage\n",
    "               (result.max_cluster<60)  # size of biggest cluster in percentage\n",
    "              ].sort_values(by='score_silhouette',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T10:14:26.227797Z",
     "start_time": "2019-04-13T10:14:26.224990Z"
    }
   },
   "outputs": [],
   "source": [
    "result.loc[129].all_features  # shows all_features column by index of row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T09:57:57.855115Z",
     "start_time": "2019-04-13T09:57:57.745959Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result[(result.score_silhouette>0.8)& # filter clusterings result based on silhouette score\n",
    "               (result.min_cluster>(2**((8-result.n_cluster)-1)+1))& # automatic formula for filter clustering with too small cluster size\n",
    "               (result.max_cluster<200/result.n_cluster)  # automatic formula for filter clustering with too big cluster size\n",
    "              ].sort_values(by='score_silhouette',ascending=False) # sort results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T16:17:28.827166Z",
     "start_time": "2019-04-13T16:16:56.447441Z"
    }
   },
   "outputs": [],
   "source": [
    "# to show result in full page : \n",
    "    # 1. press Esc to make this cell blue (vertical line of this cell)\n",
    "    # 2. then press O\n",
    "ft=['coins_spent_on_avatars_per_coins_spent','coins_on_hint_answer_again_recent',\n",
    "    'unlimited_play_per_spent','tournament_per_games']\n",
    "show_result(data = data_trans,\n",
    "            n_cluster= 4,\n",
    "            features= ft,\n",
    "            fraction= 0.3,\n",
    "            true_data= true_data )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T08:47:04.755926Z",
     "start_time": "2019-04-13T08:46:57.049847Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_features_for_clustering=['coins_spent_on_avatars_per_coins_spent','coins_on_hint_answer_again_recent',\n",
    "    'unlimited_play_per_spent','tournament_per_games']\n",
    "\n",
    "save_result(data = data_trans,\n",
    "            n_cluster = 4,\n",
    "            features = selected_features_for_clustering,\n",
    "            player_id = reduced_data.player_id,\n",
    "            name = 'function_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notify_time": "0",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "206px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
